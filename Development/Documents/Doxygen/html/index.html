<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>GigaSpace: GigaSpace</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">GigaSpace<span id="projectnumber">&#160;1.0.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('index.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">GigaSpace </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><div class="image">
<img src="GigaVoxels_red_04_test.png" alt=""/>
</div>
 <dl class="section version"><dt>Version</dt><dd>1.0.0 </dd></dl>
<dl class="section date"><dt>Date</dt><dd>2006-2015</dd></dl>
<p><br  />
 </p>
<h1><a class="anchor" id="Intro_Section"></a>
Overview</h1>
<p>[ <b><em>GigaVoxels</em></b> ] is a ray-guided out-of-core, on demand production, and smart caching library used for efficient 3D real-time visualization of highly large and detailed sparse volumetric scenes (SVO : Sparse Voxel Octree).</p>
<p>[ <b><em>GigaSpace</em></b> ] is a full-customizable out-of-core, on demand production, and smart caching library based on user-defined hierachical arbitrary space partitionning, space &amp; brick visitors, and brick producer using arbitrary data types.</p>
<p>GigaVoxels and GigaSpace are indeed the same tool.</p>
<p><br  />
 </p><hr  />
<h1><a class="anchor" id="section_Intro_Section_WhatIsGigaSpaceGigaVoxels"></a>
What is GigaSpace / GigaVoxels ?</h1>
<h2><a class="anchor" id="subsection_Intro_Section_GigaVoxels"></a>
GigaVoxels</h2>
<p>Gigavoxels is an open library made for GPU-based real-time quality rendering of very detailed and wide objects and scenes (not necessarily fuzzy or transparent). It can easily be mixed with ordinary OpenGL objects and scenes. Its secret lies in lazy evaluation: chunks of data are loaded or generated only once proven necessary for the image and only at necessary resolution. Then, they are kept in a LRU cache on GPU for next frames. Thus, hidden data have no impact at all for management, storage and rendering. Similarly, high details have no impact on cost as well as aliasing if smaller than pixel size. Gigavoxels allows to do easily the simple things, and also permits a progressive exposure of the engine depending of the customization you need. It is provided with plenty of examples to illustrate possibilities and variants, and to ease your tests and prototyping by copy-pasting.</p><ul>
<li>In the most basic usage, you are already happy with what does one of the examples (good for you: nothing to code !)</li>
<li>The most basic programming usage consists in writing the callback producer function that GigaVoxels will call at the last moment to obtain data for a given cube of space at a given resolution. This function has one part on CPU side and one part on GPU side. You might simply want to transfer data from CPU to GPU, or possibly to unpack or amplify it on GPU side. You might also generates it procedurally, or convert the requested chunk of data* from another shape structure already present in GPU memory (e.g., a VBO). footnote*: The basic use of Gigavoxels considers voxel grids since it is especially efficient to render complex data on a screen-oriented strategy: data are visited directly and in depth order without having to consider or sort any other data, while OpenGL - which is scene-oriented - has to visit and screen-project all existing elements, an especially inefficient strategy for highly complex scenes. LOD and antialiasing is just a piece of cake using voxels, and soft-shadows as well as depth-of-field are easy to obtain - and indeed, faster than sharp images. So, your producer might be a local voxelizer of a large VBO - BTW, we provide one.</li>
<li>You probably also want to add a user-defined voxel shader to tweak the data on the fly or simply to tune the appearance. In particular, it is up to you to chose what should be generated on GPU, in the producer or in the voxel shader, depending on your preferred balance between storage, performances and needs of immediate change. E.g., if you want to let a user play with a color LUT or tune hypertexture parameters, this should be done in the voxel shader for immediate feedback. But if these are fixed, rendering will be faster if data is all-cooked in the producer and kept ready-to-use in cache.</li>
<li>You might want to treat non-RGB values, or not on a simple way. Gigavoxels let you easily define the typing of voxel data. You can also customize pre and post-rendering tasks, various early tests, hints, and flag for preferred behaviors (e.g., priority strategy in strict-realtime).</li>
<li>The basic Gigavoxels relies on octree dynamic partitionning of space, which nodes corresponds to voxel bricks - if space is not empty there. But indeed, you can prefer another space partitionning scheme, such as N^3-tree, k-d tree, or even BSP-tree. You can also prefer to store something else than voxels in the local data chunck, like e.g., a piece of mesh.</li>
</ul>
<h2><a class="anchor" id="subsection_Intro_Section_GigaSpace"></a>
GigaSpace</h2>
<p>Gigaspace: May be you got it; Gigavoxels and Gigaspace are one and same thing. Gigaspace is just the generalized way of seeing the tool. So, let's now present it the general way: Gigaspace is an open GPU-based library for the efficient data management of huge data. It consists of a set of 4 components, all customizable:</p><ul>
<li>A multi-scale space-partitioning dynamic tree structure,</li>
<li>A cache-manager storing constant-size data chunks corresponding to non-empty nodes of the space partition.</li>
<li>A visitor function marching the data.</li>
<li>A data producer called when missing data are encountered by the visitor. Datatypes can be anything, 'space' can represents any variety. The basic use of Gigavoxels use octrees as tree, voxels bricks as data chunk, and volume cone-tracing* as visitor. But we provide many other examples showing other choices. footnote*: volume cone-tracing is basically volume ray-marching with 3D MIPmapping.</li>
</ul>
<h2><a class="anchor" id="subsection_Intro_Section_CudaVsOpenGLVsGLSL"></a>
Cuda vs OpenGL vs GLSL</h2>
<p>The Gigavoxels/Gigaspace data management is a CUDA library. The renderer is provided in both CUDA and GLSL. So, as long as you don't need to produce new bricks, you can render gigavoxels data totally in OpenGL without swapping to Cuda if you wish, for instance as pixel shaders binded to a mesh. Using the Cuda renderer - embedding the dynamic data management -, Gigavoxels allows various modalities of interoperability with OpenGL:</p><ul>
<li>Zbuffer integration: You can do a first pass with OpenGL then call Gigavoxels providing the OpenGL color and depth buffer so that fragments are correctly integrated. Similarly, Gigavoxels can return its color and depth buffers to OpenGL, and so one with possibly other loops. Note that hidden voxels won't render at all: interoperability keeps the gold rule "pay only for what you really see".</li>
<li>It is easy to tell Gigavoxels to render only behind or in front of a depth-buffer, which makes interactive volume clipping trivial.</li>
<li>Volume objects instances and volume material inside meshes: You can use an openGL (bounding-)box or a proxy-geometry, use their objectview matrix to rotate the volume view-angle accordingly, provide only the visible fragments to Gigavoxels, and tell it to render only behind the front depth and (optionally) in front of the rear depth. This allows for the OpenGL display of transformed instances of a given volume (e.g., to render a forest) as well as shapes seeming carved into openwork 3D material.</li>
<li>auxiliary Volumes for improved rendering effects; ray-tracing as second bounce: Gigavoxels is basically a ray-tracer so it can easily deal with reflexion, refraction, and fancy cameras such as fish-eyes. Moreover, it is especially good at blurry rendering and soft-shadows. Why not using it only to improve some bits of your classical OpenGL scene-graph rendering ? Binding Gigavoxels to a surface shader, you can easily launch the reflected, refracted or shadow rays within a voxelized version of the scene.</li>
</ul>
<h2><a class="anchor" id="subsection_Intro_Section_HistoryAndRootsOfGigavoxels"></a>
History and roots of Gigavoxels</h2>
<p>Gigavoxels draws on:</p><ul>
<li>The idea that voxel ray-tracing is a very efficient and compact way to manage highly detailed surfaces (not necessarily fuzzy or transparent), as early shown in real-time by the game industry reference John Carmack (Id Software) <a href="http://www.pcper.com/reviews/Graphics-Cards/John-Carmack-id-Tech-6-Ray-Tracing-Consoles-Physics-and-more">http://www.pcper.com/reviews/Graphics-Cards/John-Carmack-id-Tech-6-Ray-Tracing-Consoles-Physics-and-more</a> with Sparse Voxel Octrees <a href="https://www.google.fr/search?q=sparse+voxel+octree&tbm=isch">https://www.google.fr/search?q=sparse+voxel+octree&amp;tbm=isch</a> (SVO), and for high quality rendering by Jim Kajiya <a href="http://www.icg.tugraz.at/courses/lv710.087/kajiyahair.pdf">http://www.icg.tugraz.at/courses/lv710.087/kajiyahair.pdf</a> with Volumetric Textures <a href="https://www.google.fr/search?q=volumetric+textures&tbm=isch">https://www.google.fr/search?q=volumetric+textures&amp;tbm=isch</a> , first dedicated to furry Teddy bears, then generalized by Fabrice Neyret <a href="http://hal.inria.fr/index.php?action_todo=search&submit=1&s_type=advanced&submit=1&p_0=contained&v_0=volumetric%20textures&f_0=TITLE&c_0=&l_0=or&p_1=contained&v_1=texels&f_1=TITLE&c_1=&l_1=and&p_2=contained&v_2=&f_2=TITLE&c_2=&l_2=or&p_3=contained&v_3=&f_3=TITLE&c_3=&search_without_file=YES&search_in_typdoc">http://hal.inria.fr/index.php?action_todo=search&amp;submit=1&amp;s_type=advanced&amp;submit=1&amp;p_0=contained&amp;v_0=volumetric%20textures&amp;f_0=TITLE&amp;c_0=&amp;l_0=or&amp;p_1=contained&amp;v_1=texels&amp;f_1=TITLE&amp;c_1=&amp;l_1=and&amp;p_2=contained&amp;v_2=&amp;f_2=TITLE&amp;c_2=&amp;l_2=or&amp;p_3=contained&amp;v_3=&amp;f_3=TITLE&amp;c_3=&amp;search_without_file=YES&amp;search_in_typdoc</a>[0]=ART_ACL&amp;search_in_typdoc[1]=ART_SCL&amp;search_in_typdoc[2]=COMM_ACT&amp;search_in_t ypdoc[3]= COMM_SACT&amp;search_in_typdoc[4]=THESE&amp;orderby=DATEPROD&amp;ascdesc=DESC .</li>
<li>On the idea of differential cone-tracing <a href="http://en.wikipedia.org/wiki/Cone_tracing">http://en.wikipedia.org/wiki/Cone_tracing</a> which allows for zero-cost antialiasing on volume data by relying on 3D MIP-mapping.</li>
<li>On the technology of smart texture management determining visible parts on the fly then streaming or generating the data at the necessary resolution. Starting with SGI clipmaps and late variants for very large textured terrains in flight simulators, then generalized as a cache of multiscale texture tiles feeded by on demain production, by Sylvain Lefebvre and al. <a href="http://hal.inria.fr/inria-00070783">http://hal.inria.fr/inria-00070783</a></li>
<li>Cyril Crassin connected all these ideas together during his PhD to found the basis of the Gigavoxels system [refs].</li>
</ul>
<p>.................. qq vieux morceaux de texte .....................................................................................</p>
<p>The basic use of gigavoxels is an octree of small LOD voxels bricks (like 3D MIPmapping) with are kept in a LRU cache in GPU memory. Rendering is done by grid ray-tracing at appropriate LOD level. At missing bricks the user-defined producer is called to produce the necessary region at necessary resolution. So that we only produce and store what is visible accounting view frustum + visibility + mipmap LOD level.</p>
<p>But gigavoxel is more general:</p><ul>
<li>"bricks" are indeed chunks of mem that can contain what you want (voxels or VBO)</li>
<li>trees are indeed any space-partitionning tree you like.</li>
<li>"ray-tracing" is any data-visiting algorithm.</li>
<li>collected content can by RGBA, or anything you want.</li>
</ul>
<p>...........................................................................................................................................</p>
<p>L'idee du code Gigavoxel est qu'on peut faire a la fois simplement les choses simples, mais aussi des choses plus complexes si voulu. Il y a donc un certain nombre de méthodes user-define en CUDA pour fabriquer des données (l'idée est que le moteur ne fabrique les données que quand il est sur qu'on va les voir, c'est le secret pour avoir des scènes immenses et détaillées qui tiennent en mémoire et s'affichent en temps reel), pour faire le shading d'un voxel sur des données eventuellement custom (couleur+IR+UV, en astronomie), .... voire pour faire tout le rendu autrement (voire meme sans voxels du tout !). Dans la doc developpeur, on veut fournir un certains nombre d'exemples de ce qu'on peut faire, de simple ou d'innatendu, pour illustrer les différents usages (i.e. c'est pas un soft de visu scientifique), faire envie... et parceque les codeurs ne lisent jamais les manuels mais copient-collent les exemples. Par ailleurs, on a des pistes pour des usages "avancés" (par exemple, générer des VBO OpenGL avec Gigavoxel, qui servirait alors de structure de visibilité), et des améliorations (par exemple, une gestion des priorité et du temps dispo dans la fabrication "a la demande" des données, pour tenir le temps reel tout en ayant la meilleur qualité possible). On en a fait un certain nombres, mais il en manque d'importants. go</p>
<p><br  />
 </p><hr  />
<p> <br  />
</p>
<h1><a class="anchor" id="library_ProgrammingTheGigaVoxelsLibrary"></a>
Programming the GigaVoxels library</h1>
<p>You can find information on how to program with the GigaVoxels library here : <a class="el" href="_programming_the_giga_voxels_library.html">Programming the Library</a></p>
<p><br  />
 </p><div class="image">
<img src="fileFormats_02_div2.png" alt=""/>
<div class="caption">
GigaVoxels viewer : real-time / interactive voxels visualization</div></div>
<p> <br  />
 </p><hr  />
 <h1><a class="anchor" id="Research_Team_section"></a>
Research Team</h1>
<p>This research project started in 2008 at <a href="http://www.inria.fr/en/">INRIA</a> France, in the <a href="http://maverick.inria.fr/index.html">MAVERICK</a> team (ex-ARTIS team). It is now in the process of code industrialization. Team is made of researchers and engineers.</p>
<p>Please see the <a class="el" href="authors.html">Authors</a> page for contact details.</p>
<div class="image">
<img src="INRIA_CORPO_UK_RVB.png" alt=""/>
</div>
<p> Historically, the research team is also associated to :</p><ul>
<li><a href="http://www-ljk.imag.fr/ljk_en.html">Laboratoire Jean Kuntzmann</a></li>
<li><a href="http://www.cnrs.fr/index.php">CNRS</a> <div class="image">
<img src="LJK_logo.png" alt=""/>
</div>
 <div class="image">
<img src="logocnrs.png" alt=""/>
</div>
 </li>
</ul>
</div></div><!-- PageDoc -->
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8 </li>
  </ul>
</div>
</body>
</html>
